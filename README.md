# ü§ñ Qwen API

<div align="center">

![Python](https://img.shields.io/badge/Python-3.11-blue?logo=python&logoColor=white)
![FastAPI](https://img.shields.io/badge/FastAPI-0.104-green?logo=fastapi&logoColor=white)
![Docker](https://img.shields.io/badge/Docker-Compose-2496ED?logo=docker&logoColor=white)
![Ollama](https://img.shields.io/badge/Ollama-Latest-orange)

**API REST profesional para an√°lisis de texto con Inteligencia Artificial**

[Instalaci√≥n](#-instalaci√≥n) ‚Ä¢ [Uso](#-uso) ‚Ä¢ [Endpoints](#-endpoints) ‚Ä¢ [Configuraci√≥n](#-configuraci√≥n)

</div>

---

## üìã Descripci√≥n del Proyecto

**Qwen API** es una API REST construida con FastAPI que proporciona servicios de an√°lisis de texto utilizando el modelo de lenguaje **Qwen 2.5** ejecutado localmente a trav√©s de **Ollama**. 

### ¬øQu√© puede hacer?

| Tarea | Descripci√≥n |
|-------|-------------|
| üîç **Analizar** | An√°lisis detallado de cualquier texto |
| üìù **Resumir** | Resume textos largos de manera concisa |
| üòä **Sentimiento** | Detecta si el texto es positivo, negativo o neutral |
| üí° **Extraer** | Extrae las ideas principales y conceptos clave |
| üè∑Ô∏è **Keywords** | Identifica las palabras clave m√°s importantes |

### Caracter√≠sticas Principales

- ‚úÖ **100% Local** - No requiere conexi√≥n a APIs externas de IA
- ‚úÖ **Privacidad Total** - Tus datos nunca salen de tu servidor
- ‚úÖ **Dockerizado** - Despliegue f√°cil con Docker Compose
- ‚úÖ **Autenticaci√≥n** - Protecci√≥n con API Key
- ‚úÖ **Documentaci√≥n Autom√°tica** - Swagger UI y ReDoc incluidos
- ‚úÖ **Procesamiento Batch** - Analiza m√∫ltiples textos en una sola petici√≥n

---

## üèóÔ∏è Arquitectura

```mermaid
graph LR
    A[Cliente] -->|HTTP Request| B[FastAPI]
    B -->|API Key Valid| C[Router An√°lisis]
    C -->|Prompt| D[Ollama Server]
    D -->|Qwen 2.5| E[Modelo IA]
    E -->|Respuesta| D
    D -->|JSON| C
    C -->|Response| A
```

### Estructura del Proyecto

```
qwen-api/
‚îú‚îÄ‚îÄ üìÑ docker-compose.yml    # Orquestaci√≥n de contenedores
‚îú‚îÄ‚îÄ üìÑ .env                  # Variables de entorno (no subir a git)
‚îú‚îÄ‚îÄ üìÑ .env.example          # Plantilla de configuraci√≥n
‚îú‚îÄ‚îÄ üìÑ requirements.txt      # Dependencias Python
‚îÇ
‚îî‚îÄ‚îÄ üìÅ api/
    ‚îú‚îÄ‚îÄ üìÑ Dockerfile        # Imagen Docker de la API
    ‚îÇ
    ‚îî‚îÄ‚îÄ üìÅ app/
        ‚îú‚îÄ‚îÄ üìÑ __init__.py       # Paquete principal
        ‚îú‚îÄ‚îÄ üìÑ main.py           # Punto de entrada FastAPI
        ‚îú‚îÄ‚îÄ üìÑ config.py         # Configuraci√≥n con Pydantic
        ‚îú‚îÄ‚îÄ üìÑ models.py         # Modelos de request/response
        ‚îú‚îÄ‚îÄ üìÑ dependencies.py   # Autenticaci√≥n API Key
        ‚îÇ
        ‚îî‚îÄ‚îÄ üìÅ routers/
            ‚îú‚îÄ‚îÄ üìÑ __init__.py   # Paquete de routers
            ‚îú‚îÄ‚îÄ üìÑ health.py     # Endpoint de salud
            ‚îî‚îÄ‚îÄ üìÑ analisis.py   # Endpoints de an√°lisis
```

---

## üõ†Ô∏è Tecnolog√≠as Utilizadas

| Tecnolog√≠a | Versi√≥n | Prop√≥sito |
|------------|---------|-----------|
| **Python** | 3.11 | Lenguaje de programaci√≥n |
| **FastAPI** | 0.104.1 | Framework web as√≠ncrono |
| **Uvicorn** | 0.24.0 | Servidor ASGI de alto rendimiento |
| **Pydantic** | 2.5.0 | Validaci√≥n de datos |
| **Ollama** | 0.1.6 | Cliente para servidor de modelos |
| **Docker** | Latest | Contenedorizaci√≥n |
| **Qwen 2.5** | 3B | Modelo de lenguaje |

---

## üì¶ Instalaci√≥n

### Prerrequisitos

- **Docker Desktop** instalado y ejecut√°ndose
- **Git** (opcional, para clonar el repositorio)
- M√≠nimo **8 GB de RAM** disponibles
- M√≠nimo **10 GB de espacio en disco**

### Paso 1: Clonar/Descargar el Proyecto

```bash
# Opci√≥n A: Clonar con Git
git clone https://github.com/tu-usuario/qwen-api.git
cd qwen-api

# Opci√≥n B: Descargar y extraer el ZIP
```

### Paso 2: Configurar Variables de Entorno

```bash
# Crear archivo .env desde la plantilla
cp .env.example .env

# Editar con tu editor favorito
notepad .env  # Windows
nano .env     # Linux/Mac
```

**Configuraci√≥n m√≠nima requerida en `.env`:**

```env
# ¬°IMPORTANTE! Cambia esta clave por una segura
API_KEY=tu_clave_secreta_aqui

# Deja el resto con valores por defecto o ajusta seg√∫n necesites
API_PORT=8000
MODEL_NAME=qwen2.5:3b
```

### Paso 3: Iniciar los Servicios

```bash
# Construir e iniciar los contenedores
docker-compose up -d --build
```

> ‚è≥ **Nota:** La primera ejecuci√≥n puede tardar varios minutos mientras descarga el modelo Qwen 2.5 (~2GB).

### Paso 4: Verificar la Instalaci√≥n

```bash
# Verificar que los contenedores est√°n corriendo
docker-compose ps

# Probar el endpoint de salud
curl http://localhost:8000/health
```

**Respuesta esperada:**
```json
{
  "status": "healthy",
  "modelo": "qwen2.5:3b",
  "ollama_conectado": true,
  "version": "1.0.0"
}
```

### Paso 5: Descargar el Modelo (si no se descarg√≥ autom√°ticamente)

```bash
# Entrar al contenedor de Ollama
docker exec -it qwen-ollama ollama pull qwen2.5:3b
```

---

## üöÄ Uso

### Acceder a la Documentaci√≥n

Una vez iniciada la API, accede a la documentaci√≥n interactiva:

| URL | Descripci√≥n |
|-----|-------------|
| http://localhost:8000/docs | Swagger UI (interactivo) |
| http://localhost:8000/redoc | ReDoc (documentaci√≥n) |
| http://localhost:8000/ | Informaci√≥n b√°sica |

### Ejemplos de Uso con cURL

#### 1. An√°lisis de Texto

```bash
curl -X POST "http://localhost:8000/api/v1/analizar" \
  -H "Content-Type: application/json" \
  -H "X-API-Key: tu_api_key" \
  -d '{
    "texto": "La inteligencia artificial est√° revolucionando todos los sectores de la econom√≠a.",
    "tarea": "analizar",
    "temperatura": 0.7,
    "max_tokens": 512
  }'
```

#### 2. An√°lisis de Sentimiento

```bash
curl -X POST "http://localhost:8000/api/v1/analizar" \
  -H "Content-Type: application/json" \
  -H "X-API-Key: tu_api_key" \
  -d '{
    "texto": "¬°Me encanta este producto! Es incre√≠ble y funciona perfectamente.",
    "tarea": "sentimiento"
  }'
```

#### 3. Extracci√≥n de Keywords

```bash
curl -X POST "http://localhost:8000/api/v1/analizar" \
  -H "Content-Type: application/json" \
  -H "X-API-Key: tu_api_key" \
  -d '{
    "texto": "Python es un lenguaje de programaci√≥n interpretado de alto nivel con tipado din√°mico.",
    "tarea": "keywords"
  }'
```

#### 4. Procesamiento Batch

```bash
curl -X POST "http://localhost:8000/api/v1/batch" \
  -H "Content-Type: application/json" \
  -H "X-API-Key: tu_api_key" \
  -d '{
    "textos": [
      "Primer texto a analizar",
      "Segundo texto a analizar",
      "Tercer texto a analizar"
    ],
    "tarea": "resumir"
  }'
```

### Ejemplos con Python

```python
import requests

# Configuraci√≥n
API_URL = "http://localhost:8000/api/v1/analizar"
API_KEY = "tu_api_key"

# Headers de autenticaci√≥n
headers = {
    "Content-Type": "application/json",
    "X-API-Key": API_KEY
}

# Datos de la petici√≥n
data = {
    "texto": "Tu texto a analizar aqu√≠",
    "tarea": "sentimiento",
    "temperatura": 0.7,
    "max_tokens": 512
}

# Realizar petici√≥n
response = requests.post(API_URL, json=data, headers=headers)

# Procesar respuesta
if response.status_code == 200:
    resultado = response.json()
    print(f"Estado: {resultado['status']}")
    print(f"Resultado: {resultado['resultado']}")
else:
    print(f"Error: {response.status_code}")
    print(response.text)
```

---

## üì° Endpoints

### Tabla de Endpoints

| M√©todo | Endpoint | Autenticaci√≥n | Descripci√≥n |
|--------|----------|---------------|-------------|
| `GET` | `/` | ‚ùå No | Informaci√≥n de la API |
| `GET` | `/health` | ‚ùå No | Estado del servicio |
| `GET` | `/docs` | ‚ùå No | Documentaci√≥n Swagger |
| `GET` | `/redoc` | ‚ùå No | Documentaci√≥n ReDoc |
| `POST` | `/api/v1/analizar` | ‚úÖ S√≠ | An√°lisis de texto |
| `POST` | `/api/v1/batch` | ‚úÖ S√≠ | An√°lisis de m√∫ltiples textos |

### Detalle de `/api/v1/analizar`

**Request:**
```json
{
  "texto": "string (1-10000 caracteres)",
  "tarea": "analizar | resumir | sentimiento | extraer | keywords",
  "temperatura": 0.7,
  "max_tokens": 512
}
```

**Response:**
```json
{
  "status": "success",
  "tarea": "sentimiento",
  "resultado": "El texto tiene un sentimiento positivo...",
  "modelo": "qwen2.5:3b",
  "tokens_usados": 245
}
```

---

## ‚öôÔ∏è Configuraci√≥n

### Variables de Entorno

| Variable | Requerido | Default | Descripci√≥n |
|----------|-----------|---------|-------------|
| `API_KEY` | ‚úÖ S√≠ | - | Clave de autenticaci√≥n |
| `API_PORT` | ‚ùå No | 8000 | Puerto de la API |
| `API_HOST` | ‚ùå No | 0.0.0.0 | Host de la API |
| `OLLAMA_HOST` | ‚ùå No | ollama | Host de Ollama |
| `OLLAMA_PORT` | ‚ùå No | 11434 | Puerto de Ollama |
| `MODEL_NAME` | ‚ùå No | qwen2.5:3b | Modelo a usar |
| `OLLAMA_NUM_THREADS` | ‚ùå No | 8 | Threads para Ollama |
| `OLLAMA_MAX_LOADED_MODELS` | ‚ùå No | 1 | Modelos en memoria |

### Modelos Disponibles

Puedes cambiar el modelo en `.env`. Opciones recomendadas:

| Modelo | RAM Necesaria | Velocidad | Calidad |
|--------|---------------|-----------|---------|
| `qwen2.5:0.5b` | 2 GB | ‚ö°‚ö°‚ö° | ‚≠ê‚≠ê |
| `qwen2.5:1.5b` | 3 GB | ‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê |
| `qwen2.5:3b` | 4 GB | ‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê |
| `qwen2.5:7b` | 8 GB | ‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |

---

## üîß Comandos √ötiles

```bash
# Ver logs en tiempo real
docker-compose logs -f

# Ver logs solo de la API
docker-compose logs -f api

# Reiniciar servicios
docker-compose restart

# Detener servicios
docker-compose down

# Detener y eliminar vol√∫menes (¬°borra el modelo descargado!)
docker-compose down -v

# Reconstruir despu√©s de cambios
docker-compose up -d --build

# Entrar al contenedor de la API
docker exec -it qwen-api bash

# Entrar al contenedor de Ollama
docker exec -it qwen-ollama bash

# Ver modelos instalados en Ollama
docker exec -it qwen-ollama ollama list

# Descargar otro modelo
docker exec -it qwen-ollama ollama pull llama3:8b
```

---

## üîí Seguridad

### Recomendaciones para Producci√≥n

1. **Cambiar la API Key** por una clave segura y aleatoria
2. **Configurar CORS** con dominios espec√≠ficos en `main.py`
3. **Usar HTTPS** con un proxy reverso (Nginx, Traefik)
4. **Implementar rate limiting** para prevenir abuso
5. **No exponer puertos** directamente a internet sin firewall

### Ejemplo de API Key Segura

```bash
# Generar una API Key segura con Python
python -c "import secrets; print(secrets.token_urlsafe(32))"
```

---

## üêõ Soluci√≥n de Problemas

### Error: "Servicio no disponible"

```bash
# Verificar que Ollama est√° corriendo
docker-compose ps

# Ver logs de Ollama
docker-compose logs ollama

# Reiniciar Ollama
docker-compose restart ollama
```

### Error: "Modelo no encontrado"

```bash
# Descargar el modelo manualmente
docker exec -it qwen-ollama ollama pull qwen2.5:3b

# Verificar modelos instalados
docker exec -it qwen-ollama ollama list
```

### Error: "API Key inv√°lida"

- Verificar que el header es `X-API-Key` (con guiones)
- Confirmar que el valor coincide con el de `.env`
- Reiniciar la API despu√©s de cambiar `.env`

---

## üìÑ Licencia

Este proyecto est√° bajo la Licencia MIT. Consulta el archivo `LICENSE` para m√°s detalles.

---

<div align="center">

**Desarrollado con ‚ù§Ô∏è usando FastAPI y Ollama**

</div>
